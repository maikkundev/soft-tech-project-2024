{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fd666ad-633e-4c9a-a0d4-b7907e4e7d2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Import a csv or an excel file:  4.csv\n",
      "Please enter the delimiter of the csv file. It must be either \";\" or \",\":  ,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Distance Metrics:\n",
      "╒════╤═══════════╕\n",
      "│    │ Metric    │\n",
      "╞════╪═══════════╡\n",
      "│  1 │ euclidean │\n",
      "├────┼───────────┤\n",
      "│  2 │ cityblock │\n",
      "├────┼───────────┤\n",
      "│  3 │ minkowski │\n",
      "├────┼───────────┤\n",
      "│  4 │ chebyshev │\n",
      "╘════╧═══════════╛\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Type the corresponding number of the metric you would like to use for clustering:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 74.237\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "#Function to prompt the user to provide the filename.\n",
    "def get_filename():\n",
    "    \n",
    "    while True:\n",
    "        filename = input('Import a csv or an excel file: ')\n",
    "        if os.path.exists(filename):\n",
    "            if filename.split('.')[-1].lower() == 'csv' or filename.split('.')[-1].lower() == 'xlsx':\n",
    "                return filename\n",
    "            else:\n",
    "                print('Invalid file format. Please try again')\n",
    "        else:\n",
    "            print(f'Error: There is no file called: {filename}. Please try again.')\n",
    "    \n",
    "#Funtion to read the file based on its extension.    \n",
    "def read_file(filename,file_extension):\n",
    "    \n",
    "    if file_extension == 'csv':\n",
    "        while True:\n",
    "            delim = input('Please enter the delimiter of the csv file. It must be either \";\" or \",\": ')\n",
    "            if delim == ',' or delim == ';':\n",
    "                return pd.read_csv(filename, delimiter = delim)\n",
    "            else:\n",
    "                print('Invalid delimiter. Please try again.')\n",
    "    else:\n",
    "        return pd.read_excel(filename)\n",
    "\n",
    "#Function that fills the missing values with the mean of the variables\n",
    "def fill_missing_values(df):\n",
    "    df_filled = df.fillna(df.mean())\n",
    "    return df_filled   \n",
    "\n",
    "#Function that removes the duplicate instances\n",
    "def remove_duplicates(data):\n",
    "    df_without_duplicates = data.drop_duplicates()\n",
    "    return df_without_duplicates\n",
    "\n",
    "#Function that encodes categorical data into numerical\n",
    "def encode_categorical_data(data):\n",
    "    for column in data.columns[:]:\n",
    "        if data[column].dtype == 'object':\n",
    "            data[column] = pd.Categorical(data[column]).codes\n",
    "    return data\n",
    "\n",
    "#Function that removes the outliers\n",
    "def remove_outliers_iqr(df, iqr_factor=1.5):\n",
    "    conditions = []\n",
    "    for col in df.columns[:]:\n",
    "        lower_bound = df[col].quantile(5 / 100)\n",
    "        upper_bound = df[col].quantile(95 / 100)\n",
    "        condition = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "        conditions.append(condition)\n",
    "        \n",
    "    combined_condition = ~pd.concat(conditions, axis=1).any(axis=1)\n",
    "    return df[combined_condition]\n",
    "\n",
    "#Function that performs dimensionality reduction using the PCA algorithm\n",
    "def perform_pca(data):\n",
    "    if len(data.columns) >10:\n",
    "        pca = PCA(n_components = 10)\n",
    "        pca.fit(data)\n",
    "        return pd.DataFrame(pca.transform(data))\n",
    "\n",
    "#Function for the preprocess of the data\n",
    "def data_preprocess_for_the_clustering_algorithms(data):\n",
    "    data = fill_missing_values(data)\n",
    "    data = remove_duplicates(data)\n",
    "    data = encode_categorical_data(data)\n",
    "    data = remove_outliers_iqr(data)\n",
    "    data = perform_pca(data)\n",
    "    return data    \n",
    "\n",
    "#Function that implements the Hierarchical clustering algorithm\n",
    "def hierarchical_clustering(data, linkage='ward'):\n",
    "    data = data_preprocess_for_the_clustering_algorithms(data.iloc[:, :-1])\n",
    "    metrics = {\n",
    "    \"1\": \"euclidean\",\n",
    "    \"2\": \"cityblock\",\n",
    "    \"3\": \"minkowski\",\n",
    "    \"4\": \"chebyshev\" \n",
    "    }\n",
    "    \n",
    "    print(\"Available Distance Metrics:\")\n",
    "    print(tabulate(metrics.items(), headers=[\"Metric\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            metric_choice = input('Type the corresponding number of the metric you would like to use for clustering: ')\n",
    "            metric_choice = int(metric_choice)\n",
    "            if 1 <= metric_choice <= 4:  # Use inclusive range for valid options (1-4)\n",
    "                break\n",
    "            else:\n",
    "                print('There are only 4 options. Please try again')\n",
    "                continue\n",
    "        except ValueError:\n",
    "            print('Invalid input. Please enter a number between 1 and 4.')\n",
    "\n",
    "    metric = metrics[str(metric_choice)]\n",
    "            \n",
    "    distance_matrix = pdist(data, metric=metric)\n",
    "    cluster_result = hierarchy.linkage(distance_matrix, method=linkage)\n",
    "    cluster_labels = fcluster(cluster_result, 2, criterion='maxclust')\n",
    "    silhouette = round((silhouette_score(data, cluster_labels, metric=metric) * 100), 3)\n",
    "    print(f\"Silhouette Score: {silhouette}\")\n",
    "    \n",
    "filename = get_filename()\n",
    "file_extension = filename.split('.')[-1].lower()\n",
    "data_frame = read_file(filename,file_extension)\n",
    "hierarchical_clustering(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd68447-3a6d-4eee-869c-78fe7e342d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
